{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEZyez0skHHh"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Nils Knieling\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZv3J78QCS_"
      },
      "source": [
        "# Building AI-powered applications using LocalAI and Llama 2 in the Google Cloud\n",
        "\n",
        "[![Open in Colab](https://img.shields.io/badge/Open%20in%20Colab-%23F9AB00.svg?logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/Cyclenerd/toolbox/blob/master/notebooks/LocalAI_Llama2.ipynb)\n",
        "[![Open in Vertex AI Workbench](https://img.shields.io/badge/Open%20in%20Vertex%20AI%20Workbench-%234285F4.svg?logo=googlecloud&logoColor=white)](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/Cyclenerd/toolbox/master/notebooks/LocalAI_Llama2.ipynb)\n",
        "[![View on GitHub](https://img.shields.io/badge/View%20on%20GitHub-181717.svg?logo=github&logoColor=white)](https://github.com/Cyclenerd/toolbox/blob/master/notebooks/LocalAI_Llama2.ipynb)\n",
        "\n",
        "![Screenshot](https://raw.githubusercontent.com/Cyclenerd/toolbox/master/notebooks/chatbot-ui-llama2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJX8Z6UP5dJ"
      },
      "source": [
        "## Setup Google Cloud environment\n",
        "\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M9YVe5-xOfye"
      },
      "outputs": [],
      "source": [
        "# @markdown ✏️ Replace the placeholder text below:\n",
        "\n",
        "# Please fill in these values.\n",
        "project_id = \"test-nils-ai\"  # @param {type:\"string\"}\n",
        "region = \"us-central1\"  # @param {type:\"string\"}\n",
        "llm_models_bucket = \"nils-llm-models\"  # @param {type:\"string\"}\n",
        "llm_models_disk = \"disk-nils-llm-models\"  # @param {type:\"string\"}\n",
        "vpc_network_name = \"vpc-test-nils-ai\" # @param {type:\"string\"}\n",
        "docker_registry_name = \"docker-test-nils-ai\" # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
        "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
        "assert llm_models_bucket, \"⚠️ Please provide a Google Cloud storage bucket to store LLM models\"\n",
        "assert llm_models_disk, \"⚠️ Please provide a Google Cloud storage disk to store LLM models\"\n",
        "assert vpc_network_name, \"⚠️ Please provide a VPC network name\"\n",
        "assert docker_registry_name, \"⚠️ Please provide a Artifact Registry repository name\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project \"{project_id}\"\n",
        "!gcloud config set storage/parallel_composite_upload_enabled \"True\"\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "1-qJSxCaNm7o"
      },
      "outputs": [],
      "source": [
        "#@markdown ### (Colab only!) Authenticate your Google Cloud Account\n",
        "\n",
        "# Authenticate gcloud.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P36weIg5VURP"
      },
      "outputs": [],
      "source": [
        "#@markdown ###  Check authenticated user\n",
        "current_user = !gcloud auth list \\\n",
        "  --filter=\"status:ACTIVE\" \\\n",
        "  --format=\"value(account)\" \\\n",
        "  --quiet\n",
        "\n",
        "current_user = current_user[0]\n",
        "print(f\"Current user: {current_user}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YPTem9iQOpxm"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Enable APIs\n",
        "\n",
        "# Enable APIs\n",
        "my_google_apis = [\n",
        "    \"storage.googleapis.com\",\n",
        "    \"compute.googleapis.com\",\n",
        "    \"artifactregistry.googleapis.com\",\n",
        "    \"container.googleapis.com\",\n",
        "    \"containerscanning.googleapis.com\",\n",
        "    \"cloudbuild.googleapis.com\",\n",
        "    \"notebooks.googleapis.com\",\n",
        "    \"aiplatform.googleapis.com\",\n",
        "]\n",
        "\n",
        "for api in my_google_apis :\n",
        "  print(f\"Enable API: {api}\")\n",
        "  !gcloud services enable \"{api}\" \\\n",
        "    --project=\"{project_id}\" \\\n",
        "    --quiet\n",
        "\n",
        "print(\"☑️ OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSzz9cJzOFRc"
      },
      "source": [
        "### Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6PhbAE1nujhn"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create storage bucket for data\n",
        "\n",
        "!gcloud storage buckets create 'gs://{llm_models_bucket}' \\\n",
        "  --location='{region}' \\\n",
        "  --uniform-bucket-level-access \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")\n",
        "print(f\"Open in console: https://console.cloud.google.com/storage/browser/{llm_models_bucket}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZL8MlWO1ohv"
      },
      "source": [
        "### Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "so6huCNF1HFe"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create disk for LLM models\n",
        "\n",
        "!gcloud compute disks create \"{llm_models_disk}\" \\\n",
        "  --type=\"pd-ssd\" \\\n",
        "  --size=\"75GB\" \\\n",
        "  --zone=\"{region}-b\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TziqFBZs9afV"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0PPqkGD49e_l"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create a regional VPC network\n",
        "\n",
        "!gcloud compute networks create \"{vpc_network_name}\" \\\n",
        "  --subnet-mode=\"custom\" \\\n",
        "  --bgp-routing-mode=\"regional\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nZi3kqwFcE-i"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create a subnet in the region\n",
        "\n",
        "!gcloud compute networks subnets create \"{vpc_network_name}-{region}\" \\\n",
        "  --network=\"{vpc_network_name}\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --range=\"10.128.1.0/24\" \\\n",
        "  --enable-private-ip-google-access \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GDsH8YrO-QJy"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create firewall rules\n",
        "\n",
        "!gcloud compute firewall-rules create \"{vpc_network_name}-allow-default\" \\\n",
        "  --allow=\"tcp:22,tcp:3389,icmp\" \\\n",
        "  --network=\"{vpc_network_name}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "!gcloud compute firewall-rules create \"{vpc_network_name}-allow-http\" \\\n",
        "  --allow=\"tcp:80,tcp:443,tcp:3000,tcp:8080\" \\\n",
        "  --network=\"{vpc_network_name}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GcXUqsOprVV1"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create router in region\n",
        "\n",
        "!gcloud compute routers create \"router-{vpc_network_name}-{region}\" \\\n",
        "  --network=\"{vpc_network_name}\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j4R3hpparsyI"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Add NAT to router in region\n",
        "\n",
        "!gcloud compute routers nats create \"nat-{vpc_network_name}-{region}\" \\\n",
        "  --router=\"router-{vpc_network_name}-{region}\"  \\\n",
        "  --auto-allocate-nat-external-ips \\\n",
        "  --nat-all-subnet-ip-ranges \\\n",
        "  --enable-logging \\\n",
        "  --log-filter=ERRORS_ONLY \\\n",
        "  --min-ports-per-vm=256 \\\n",
        "  --region=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5hejBaTSOn1"
      },
      "source": [
        "### Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNKB1sscSan4"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create Artifact Registry for Docker cointainer images\n",
        "\n",
        "!gcloud artifacts repositories create \"{docker_registry_name}\" \\\n",
        "  --repository-format=\"docker\"\\\n",
        "  --description=\"Docker contrainer registry\" \\\n",
        "  --location=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtaAl_q6W_PP"
      },
      "source": [
        "## Container\n",
        "\n",
        "Build Docker container images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_QdJA3h9qTf"
      },
      "source": [
        "### LocalAI\n",
        "\n",
        "* GitHub: <https://github.com/go-skynet/LocalAI#readme>\n",
        "* Website: <https://localai.io/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "OMLgQ3ZoWFCH"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Build LocalAI container image from GitHub source\n",
        "\n",
        "# Please fill in these values.\n",
        "localai_git_repo = \"https://github.com/go-skynet/LocalAI.git\"  # @param {type:\"string\"}\n",
        "localai_git_revision = \"master\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert localai_git_repo, \"⚠️ Please provide the LocalAI Git source repository\"\n",
        "assert localai_git_revision, \"⚠️ Please provide the LocalAI Git source revision\"\n",
        "\n",
        "!gcloud builds submit \"{localai_git_repo}\" \\\n",
        "  --git-source-revision=\"{localai_git_revision}\" \\\n",
        "  --tag \"{region}-docker.pkg.dev/{project_id}/{docker_registry_name}/localai:latest\" \\\n",
        "  --machine-type=\"e2-highcpu-8\" \\\n",
        "  --timeout=\"1h\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --default-buckets-behavior=\"regional-user-owned-bucket\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRl8Z6ssoDVa"
      },
      "source": [
        "### Chatbot UI\n",
        "\n",
        "* GitHub: <https://github.com/mckaywrigley/chatbot-ui#readme>\n",
        "* Website: <https://www.chatbotui.com/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QcSrnwu6oIJS"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Build Chatbot UI container image from GitHub source\n",
        "\n",
        "# Please fill in these values.\n",
        "chatbot_ui_git_repo = \"https://github.com/mckaywrigley/chatbot-ui.git\"  # @param {type:\"string\"}\n",
        "chatbot_ui_git_revision = \"main\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert chatbot_ui_git_repo, \"⚠️ Please provide the LocalAI Git source repository\"\n",
        "assert chatbot_ui_git_revision, \"⚠️ Please provide the LocalAI Git source revision\"\n",
        "\n",
        "!gcloud builds submit \"{chatbot_ui_git_repo}\" \\\n",
        "  --git-source-revision=\"{chatbot_ui_git_revision}\" \\\n",
        "  --tag \"{region}-docker.pkg.dev/{project_id}/{docker_registry_name}/chatbot-ui:latest\" \\\n",
        "  --machine-type=\"e2-highcpu-8\" \\\n",
        "  --timeout=\"1h\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --default-buckets-behavior=\"regional-user-owned-bucket\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCKhZfDJOYsn"
      },
      "source": [
        "## Workbench\n",
        "\n",
        "Deploy Vertex user-managed notebooks instance in VPC network.\n",
        "\n",
        "Machine type recommendation: [`n1-standard-2` in `us-central1`](https://gcloud-compute.com/us-central1/n1-standard-2.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "f6vQJ0iAGVmJ"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Create user-managed instance for workbench/notebooks\n",
        "\n",
        "# This code snippet may run for a few (>5) minutes.\n",
        "\n",
        "# Please fill in these values.\n",
        "workbench_machine_type = \"n1-standard-2\"  # @param {type:\"string\"}\n",
        "workbench_data_disk_gb = \"250\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert workbench_machine_type, \"⚠️ Please provide a Google Compute Engine machine type\"\n",
        "assert workbench_data_disk_gb, \"⚠️ Please provide a data disk size in GiB\"\n",
        "\n",
        "print(\"Please wait...\")\n",
        "\n",
        "# OS images: https://gcloud-compute.com/images.html\n",
        "!gcloud notebooks instances create \"workbench-{vpc_network_name}\" \\\n",
        "  --machine-type=\"{workbench_machine_type}\" \\\n",
        "  --vm-image-project=\"deeplearning-platform-release\"\\\n",
        "  --vm-image-family=\"tf-latest-gpu-ubuntu-2004-py310\" \\\n",
        "  --boot-disk-size=\"50\" \\\n",
        "  --boot-disk-type=\"PD_SSD\" \\\n",
        "  --data-disk-size=\"{workbench_data_disk_gb}\"\\\n",
        "  --data-disk-type=\"PD_SSD\" \\\n",
        "  --network=\"{vpc_network_name}\" \\\n",
        "  --subnet=\"{vpc_network_name}-{region}\" \\\n",
        "  --subnet-region=\"{region}\" \\\n",
        "  --no-public-ip \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --location=\"{region}-b\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")\n",
        "print(f\"Open Workbench in console: https://console.cloud.google.com/vertex-ai/workbench/user-managed?project={project_id}\")\n",
        "print(f\"Open Compute Engine in console: https://console.cloud.google.com/compute/instancesDetail/zones/{region}-b/instances/workbench-{vpc_network_name}?project={project_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9MThyBa5llE"
      },
      "source": [
        "### Prepare LLM disk\n",
        "\n",
        "Stop workbench instance and attach created disk for LLM models.\n",
        "\n",
        "Start workbench instance and open JupyterLab:\n",
        "\n",
        "1. In the terminal,\n",
        "use the `lsblk` command to list the disks that are attached to your instance and find the disk that you want to format and mount.\n",
        "\n",
        "  ```text\n",
        "  (base) jupyter@workbench-vpc-test-nils-ai:~$ sudo lsblk\n",
        "  NAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n",
        "  loop0     7:0    0  55.7M  1 loop /snap/core18/2785\n",
        "  loop1     7:1    0  63.5M  1 loop /snap/core20/1891\n",
        "  loop2     7:2    0  63.5M  1 loop /snap/core20/1974\n",
        "  loop3     7:3    0 344.1M  1 loop /snap/google-cloud-cli/143\n",
        "  loop4     7:4    0  91.9M  1 loop /snap/lxd/24061\n",
        "  loop5     7:5    0  53.3M  1 loop /snap/snapd/19361\n",
        "  loop6     7:6    0  53.3M  1 loop /snap/snapd/19457\n",
        "  sda       8:0    0    50G  0 disk\n",
        "  ├─sda1    8:1    0  49.9G  0 part /\n",
        "  ├─sda14   8:14   0     4M  0 part\n",
        "  └─sda15   8:15   0   106M  0 part /boot/efi\n",
        "  sdb       8:16   0   750G  0 disk /home/jupyter\n",
        "  sdc       8:32   0    75G  0 disk\n",
        "  ```\n",
        "\n",
        "  In this example it is disk `sdc`.\n",
        "\n",
        "1. Format the disk using the `mkfs` tool.\n",
        "This command deletes all data from the specified disk, so make sure that you specify the disk device correctly.\n",
        "\n",
        "  ```bash\n",
        "  sudo mkfs.ext4 -m 0 -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/sdc\n",
        "  ```\n",
        "\n",
        "1. Create a directory that serves as the mount point for the new disk on the VM.\n",
        "\n",
        "  ```bash\n",
        "  sudo mkdir -p /mnt/disks/models\n",
        "  ```\n",
        "\n",
        "1. Use the `mount` tool to mount the disk to the instance, and enable the discard option:\n",
        "\n",
        "  ```bash\n",
        "  sudo mount -o discard,defaults /dev/sdc /mnt/disks/models\n",
        "  ```\n",
        "\n",
        "1. Grant write access to the disk for all users.\n",
        "\n",
        "  ```bash\n",
        "  sudo chmod a+w /mnt/disks/models\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62_lORBpzYfP"
      },
      "source": [
        "Run the following steps in the terminal of your new workbench instance:\n",
        "\n",
        "```bash\n",
        "# Install git lfs\n",
        "curl -s \"https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh\" \\\n",
        "  | sudo bash\n",
        "sudo apt-get install git-lfs\n",
        "git lfs install\n",
        "```\n",
        "\n",
        "Download models... (from [Hugging Face](https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/tree/main))\n",
        "\n",
        "```bash\n",
        "mkdir -p models\n",
        "cd models\n",
        "# curl -OLp https://huggingface.co/TheBloke/Llama-2-7B-GGML/resolve/main/llama-2-7b.ggmlv3.q4_0.bin\n",
        "# curl -OLp https://huggingface.co/TheBloke/Llama-2-13B-GGML/resolve/main/llama-2-13b.ggmlv3.q4_0.bin\n",
        "# curl -OLp https://huggingface.co/TheBloke/Llama-2-70B-GGML/resolve/main/llama-2-70b.ggmlv3.q4_0.bin\n",
        "# Chat\n",
        "# curl -OLp https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_0.bin\n",
        "curl -OLp https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_0.bin\n",
        "# curl -OLp https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/resolve/main/llama-2-70b-chat.ggmlv3.q4_0.bin\n",
        "# German\n",
        "# https://huggingface.co/flozi00/Llama-2-13B-german-assistant-v2\n",
        "# curl -OLp https://huggingface.co/TheBloke/llama-2-13B-German-Assistant-v2-GGML/resolve/main/llama-2-13b-german-assistant-v2.ggmlv3.q4_0.bin\n",
        "```\n",
        "\n",
        "Copy to bucket:\n",
        "\n",
        "```bash\n",
        "gcloud storage cp -r models gs://nils-llm-models/\n",
        "```\n",
        "\n",
        "Copy to LLM model to disk:\n",
        "\n",
        "```bash\n",
        "# From disk\n",
        "cp models/llama-2-13b-chat.ggmlv3.q4_0.bin \"/mnt/disks/models/\"\n",
        "# or from bucket\n",
        "#gcloud storage cp gs://nils-llm-models/models/llama-2-13b-chat.ggmlv3.q4_0.bin \"/mnt/disks/models/\"\n",
        "```\n",
        "\n",
        "Create config and \"fake\" `gpt-3.5-turbo` model. Create `gpt-3.5-turbo.yaml` file:\n",
        "\n",
        "```bash\n",
        "nano gpt-3.5-turbo.yaml\n",
        "```\n",
        "\n",
        "Add text to file:\n",
        "\n",
        "```text\n",
        "name: gpt-3.5-turbo\n",
        "parameters:\n",
        "  model: llama-2-13b-chat.ggmlv3.q4_0.bin\n",
        "  top_k: 80\n",
        "  temperature: 0.2\n",
        "  top_p: 0.7\n",
        "context_size: 1024\n",
        "stopwords:\n",
        "- \"HUMAN:\"\n",
        "- \"GPT:\"\n",
        "roles:\n",
        "  user: \" \"\n",
        "  system: \" \"\n",
        "template:\n",
        "  completion: completion\n",
        "  chat: gpt4all\n",
        "backend: llama\n",
        "```\n",
        "\n",
        "Create `completion.tmpl` file:\n",
        "\n",
        "```bash\n",
        "nano completion.tmpl\n",
        "```\n",
        "\n",
        "Add:\n",
        "\n",
        "```text\n",
        "{{.Input}}\n",
        "```\n",
        "\n",
        "Create `gpt4all.tmpl` file:\n",
        "\n",
        "```bash\n",
        "nano gpt4all.tmpl\n",
        "```\n",
        "\n",
        "Add:\n",
        "\n",
        "```text\n",
        "The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.\n",
        "### Prompt:\n",
        "{{.Input}}\n",
        "### Response:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV7qO839uu27"
      },
      "source": [
        "Stop the workbench instance and detach the disk with the LLM model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeJ4ltc0BDxc"
      },
      "source": [
        "## Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKdxhDuSrcTX"
      },
      "source": [
        "### LocalAI\n",
        "\n",
        "Machine type recommendation: [`c2d-highcpu-32` in `us-central1`](https://gcloud-compute.com/us-central1/c2d-highcpu-32.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or3LrcE6rfEk"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Deploy VM instance with LocalAI container image\n",
        "\n",
        "#@markdown ⚠️ Warning: `localai_cpu_cores` must be the number of physical cores!\n",
        "#@markdown Overbooking the CPU degrades performance notably.\n",
        "\n",
        "# Please fill in these values.\n",
        "localai_machine_type = \"c2d-highcpu-32\"  # @param {type:\"string\"}\n",
        "localai_cpu_cores = \"16\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert localai_machine_type, \"⚠️ Please provide a Google Compute Engine machine type\"\n",
        "assert localai_cpu_cores, \"⚠️ Please provide Google Compute Engine machine type CPU core count\"\n",
        "\n",
        "!gcloud compute instances create-with-container \"localai-{vpc_network_name}\" \\\n",
        "  --machine-type=\"{localai_machine_type}\" \\\n",
        "  --network-interface=\"subnet={vpc_network_name}-{region},no-address\" \\\n",
        "  --image-project=\"cos-cloud\" \\\n",
        "  --image-family=\"cos-stable\" \\\n",
        "  --boot-disk-size=\"25GB\" \\\n",
        "  --boot-disk-type=\"pd-ssd\" \\\n",
        "  --container-image=\"{region}-docker.pkg.dev/{project_id}/{docker_registry_name}/localai:latest\" \\\n",
        "  --container-mount-disk=\"mode=ro,mount-path=/build/models,name={llm_models_disk},partition=0\" \\\n",
        "  --disk=\"boot=no,device-name={llm_models_disk},mode=ro,name={llm_models_disk}\" \\\n",
        "  --container-env=\"THREADS={localai_cpu_cores}\" \\\n",
        "  --zone=\"{region}-b\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XGx1w5br1-6L"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Generate hostname for later use\n",
        "\n",
        "localai_global_dns_name=f\"localai-{vpc_network_name}.c.{project_id}.internal\"\n",
        "localai_base_url=f\"http://{localai_global_dns_name}:8080\"\n",
        "\n",
        "print(f\"Global internal DNS name: {localai_global_dns_name}\\n\")\n",
        "print(f\"Models: curl '{localai_base_url}/v1/models'\")\n",
        "print(f\"Completions: curl '{localai_base_url}/v1/chat/completions'\")\n",
        "\n",
        "print(\"\\n☑️ OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kxb_rrb4_wp"
      },
      "source": [
        "Test from workbench instance:\n",
        "\n",
        "```bash\n",
        "time curl \"http://[LOCALAI_BASE_URL]/v1/chat/completions\" -H \"Content-Type: application/json\" -d '{\n",
        "     \"model\": \"gpt-3.5-turbo\",\n",
        "     \"messages\": [{\"role\": \"user\", \"content\": \"How are you?\"}],\n",
        "     \"temperature\": 0.9\n",
        "   }'\n",
        "```\n",
        "\n",
        "Example:\n",
        "\n",
        "```bash\n",
        "time curl 'http://localai-vpc-test-nils-ai.c.test-nils-ai.internal:8080/v1/chat/completions' -H \"Content-Type: application/json\" -d '{\n",
        "     \"model\": \"gpt-3.5-turbo\",\n",
        "     \"messages\": [{\"role\": \"user\", \"content\": \"How are you?\"}],\n",
        "     \"temperature\": 0.9\n",
        "   }'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jip_UTEnGIsj"
      },
      "source": [
        "### Chatbot UI\n",
        "\n",
        "Machine type recommendation: [`e2-medium` in `us-central1`](https://gcloud-compute.com/us-central1/e2-medium.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BTQeWPlnGLcc"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Deploy VM instance with Chatbot UI container image\n",
        "\n",
        "#@markdown ⚠️ Warning: This instance gets a public IPv4 address!\n",
        "\n",
        "# Please fill in these values.\n",
        "chatbot_ui_machine_type = \"e2-medium\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert chatbot_ui_machine_type, \"⚠️ Please provide a Google Compute Engine machine type\"\n",
        "\n",
        "!gcloud compute instances create-with-container \"chatbot-ui-{vpc_network_name}\" \\\n",
        "  --machine-type=\"{chatbot_ui_machine_type}\" \\\n",
        "  --network-interface=\"subnet={vpc_network_name}-{region}\" \\\n",
        "  --image-project=\"cos-cloud\" \\\n",
        "  --image-family=\"cos-stable\" \\\n",
        "  --boot-disk-size=\"10GB\" \\\n",
        "  --boot-disk-type=\"pd-ssd\" \\\n",
        "  --container-image=\"{region}-docker.pkg.dev/{project_id}/{docker_registry_name}/chatbot-ui:latest\" \\\n",
        "  --container-env=\"OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX,OPENAI_API_HOST={localai_base_url}\" \\\n",
        "  --zone=\"{region}-b\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boXqU_ppwmu2"
      },
      "source": [
        "You can now connect with your browser to the external IP on port 3000 and chat with Llama 2 🦙💬\n",
        "\n",
        "URL:\n",
        "\n",
        "```text\n",
        "http://[EXTERNAL_IP]:3000/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT6u0A4_COI_"
      },
      "source": [
        "## Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-oSMSxCpWhi",
        "outputId": "f09755c7-031b-41aa-be87-1df0fcc4df6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                         ZONE           MACHINE_TYPE    PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP  STATUS\n",
            "chatbot-ui-vpc-test-nils-ai  us-central1-b  e2-medium                    10.128.1.16               TERMINATED\n",
            "localai-vpc-test-nils-ai     us-central1-b  c2d-highcpu-32               10.128.1.15               RUNNING\n",
            "workbench-vpc-test-nils-ai   us-central1-b  n1-standard-2                10.128.1.8                RUNNING\n"
          ]
        }
      ],
      "source": [
        "# Lists GCE instances\n",
        "!gcloud compute instances list \\\n",
        "  --project=\"{project_id}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGFOHk4QDpsY"
      },
      "outputs": [],
      "source": [
        "# List notebooks instances in a region/location\n",
        "!gcloud notebooks instances list \\\n",
        "  --location=\"{region}-b\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfGv05ZTiE_z"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_hg_Gyx3OuN"
      },
      "source": [
        "### Workbench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVvQ0EBMLG2l"
      },
      "outputs": [],
      "source": [
        "# Delete user-managed notebooks/workbench instance\n",
        "print(\"Please wait...\")\n",
        "!gcloud notebooks instances delete \"workbench-{vpc_network_name}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --location=\"{region}-b\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcNEyvPiuen3"
      },
      "source": [
        "### Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTMdU13mukm5"
      },
      "outputs": [],
      "source": [
        "# Delete LocalAI instance\n",
        "print(\"Please wait...\")\n",
        "!gcloud compute instances delete \"localai-{vpc_network_name}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --zone=\"{region}-b\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EguGDgwpnC5"
      },
      "outputs": [],
      "source": [
        "# Delete Chatbot UI instance\n",
        "print(\"Please wait...\")\n",
        "!gcloud compute instances delete \"chatbot-ui-{vpc_network_name}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --zone=\"{region}-b\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRIHgfxBg5c7"
      },
      "source": [
        "### Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8zjoO3-vHeY"
      },
      "outputs": [],
      "source": [
        "# Delete data bucket\n",
        "!gcloud storage rm -r 'gs://{llm_models_bucket}' \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GIHM1w52A7y"
      },
      "source": [
        "### Disk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGRXAJZA2DXp"
      },
      "outputs": [],
      "source": [
        "# Delete disk for LLM models\n",
        "!gcloud compute disks delete \"{llm_models_disk}\" \\\n",
        "  --zone=\"{region}-b\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5YmsWt3hCqW"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBeuf2K6sanC"
      },
      "outputs": [],
      "source": [
        "# Delete NAT router in region\n",
        "print(\"Please wait...\")\n",
        "!gcloud compute routers nats delete \"nat-{vpc_network_name}-{region}\" \\\n",
        "  --router=\"router-{vpc_network_name}-{region}\"  \\\n",
        "  --region=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUffwSOLsodd"
      },
      "outputs": [],
      "source": [
        "# Delete router\n",
        "print(\"Please wait...\")\n",
        "!gcloud compute routers delete \"router-{vpc_network_name}-{region}\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJmcqaxFtCV5"
      },
      "outputs": [],
      "source": [
        "# Delete subnet\n",
        "print(\"Please wait...\")\n",
        "!gcloud compute networks subnets delete \"{vpc_network_name}-{region}\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete firewall rules\n",
        "\n",
        "!gcloud compute firewall-rules delete \"{vpc_network_name}-allow-default\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "!gcloud compute firewall-rules delete \"{vpc_network_name}-allow-http\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZe3sTaXtKpM"
      },
      "outputs": [],
      "source": [
        "# Delete VPC\n",
        "print(\"Please wait...\")\n",
        "!gcloud compute networks delete \"{vpc_network_name}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpSvqg2iTS7W"
      },
      "source": [
        "### Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn9pmYO66Q2R"
      },
      "outputs": [],
      "source": [
        "# Delete old container images in Artifact Registry\n",
        "\n",
        "gcr_cleaner_cloud_build_config=f\"\"\"# Delete old container images\n",
        "steps:\n",
        "  - name: 'cyclenerd/google-cloud-gcp-tools-container:latest'\n",
        "    entrypoint: 'gcr-cleaner-cli'\n",
        "    args:\n",
        "      - '-repo'\n",
        "      - '{region}-docker.pkg.dev/{project_id}/{docker_registry_name}'\n",
        "      - '-recursive'\n",
        "\"\"\"\n",
        "\n",
        "with open(\"gcr-cleaner.yaml\", \"w\") as text_file:\n",
        "    print(gcr_cleaner_cloud_build_config, file=text_file)\n",
        "\n",
        "!gcloud builds submit --no-source \\\n",
        "  --config=\"./gcr-cleaner.yaml\" \\\n",
        "  --timeout=\"10m\" \\\n",
        "  --region=\"{region}\" \\\n",
        "  --default-buckets-behavior=\"regional-user-owned-bucket\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hCab_r2TWYl"
      },
      "outputs": [],
      "source": [
        "# Delete Artifact Registry for Docker cointainer images\n",
        "!gcloud artifacts repositories delete \"{docker_registry_name}\" \\\n",
        "  --location=\"{region}\" \\\n",
        "  --project=\"{project_id}\" \\\n",
        "  --quiet"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
